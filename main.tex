\documentclass{article}
\documentclass[utf8x, 12pt]{G7-32} % Стиль (по умолчанию будет 14pt)
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{mathtext}
\usepackage[numberright]{eskdplain}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{mathtext}
\usepackage[T1,T2A]{fontenc}
\usepackage[english,bulgarian,ukranian,russian]{babel}
\usepackage[argument]{graphicx}
\graphicspath{{pics/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\usepackage{geometry} % Меняем поля страницы
\geometry{left=2cm}% левое поле
\geometry{right=1.5cm}% правое поле
\geometry{top=1cm}% верхнее поле
\geometry{bottom=2cm}% нижнее поле

\begin{document}
    \begin{center} 
    \large МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ РОССИЙСКОЙ ФЕДЕРАЦИИ

федеральное государственное автономное образовательное учреждение высшего образования

Национальный исследовательский нижегородский государственный университет им. Н.И. Лобачевского

Институт информационных технологий, математики и механики \\
Кафедра математического обеспечения и суперкомпьютерных технологий\\[3.5cm] 
    
    \huge Отчёт по практике \\[0.6cm] % название работы, затем отступ 0,6см
    \\ 
    \huge{Тема :}\\[0.6cm]
    \huge Сети Generative adversarial networks для синтеза изображений по текстовому описанию\\[7.7cm]
    
    
    \end{center} 
    
    \begin{flushright}
    \large \textbf{Выполнил:} \\
    студент гр. 381706-1 \\
    Митягина Дарья Сергеевна \\
    \textbf{Научный руководитель:} \\
    Профессор, доктор технических наук\\
    Турлапов Вадим Евгеньевич \\
    [3.7cm]
    \end{flushright}
    
    
    % \vfill 
    
    \begin{center} 
    \large Нижний Новгород 2019
    \end{center} 
    
    \thispagestyle{empty}
    \newpage
      \begin{center}
    %   Содержание
        \tableofcontents
      \end{center}
    \newpage
    \begin{center} 
    \section{Введение}
    %   \huge \textbf{Введение} \\[1.3cm]
    \end{center} 
      \large Oдной из самых сложных проблем в мире Computer Vision является синтез высококачественных изображений из текстовых описаний. Без сомнения, это интересно и полезно, но современные системы искусственного интеллекта далеки от этой цели.

    Генерация изображений имеет множество возможных применений в
    будущем, когда технологии будут готовы для коммерческого применения. 
    Люди смогут создавать схему расположения мебели для своего дома, просто описывая ее на компьютере, а не тратя много часов на поиск нужного дизайна.\\ 
    Создатели контента смогут творить в более тесном сотрудничестве с машиной, используя естественный язык.
    Кроме того, данная тема может стать более интересной, если ее развить. А именно, перевести задачу из генерации 2d изображения в построение 3d сцены и даже, возможно, формирование видео материалов с использование полученных сцен.\\ \\
    В данном отчете будут \\
    - рассмотрены уже существующие решения задачи генерации изображений по текстовому описанию\\
    - разобраны основные составляющие части программной реализации этих решений\\
    - описаны основные положения из теории, лежащие в основе выбранных методов\\
    - предъявлены результаты некоторых проведенных экспериментов\\ \\
    % \newpage
    % \begin{center} 
    % \section{Постановка задачи}
    % \huge \textbf{Постановка задачи} \\[1.3cm]
    \large \textbf{Постановка задачи :} \\ \\
    % \end{center} 
      \large 1. Исследовать различные публикации на поставленную тему.\\
             2. Изучить средства и методы решения задачи синтеза изображений из их словесного описания.\\
             3. Начать проведение практических экспериментов.\\
    \newpage
    \begin{center} 
    \section{Необходимый теоретический минимум}
    % \huge \textbf{Необходимый теоретический минимум} \\[1.3cm]
    \end{center} 
      \large \textbf{1. Граф сцены}\\
      Граф сцены представляет структуру, которая содержит логическое и зачастую (но не обязательно) пространственное представление графической сцены. Определение графа сцены нечёткое, поскольку программисты, осуществляющие его реализацию в приложениях, — и, в частности, в индустрии разработки игр — берут базовые принципы и адаптируют их для применения в конкретных приложениях. Это означает, что нет договорённости о том, каким должен быть граф сцены.

    Граф сцены представляет собой набор узлов такой структуры, как граф или дерево. Узел дерева может иметь множество потомков, но зачастую только одного предка, причём действие предка распространяется на все его дочерние узлы; эффект действия, выполненного над группой, автоматически распространяется на все её элементы. Во многих программах ассоциирование матрицы преобразования на уровне любой группы и умножение таких матриц представляет собой эффективный и естественный способ обработки таких действий. Общей особенностью, к примеру, является способность группировать связанные формы/объекты в составной объект, который можно перемещать, трансформировать, выбирать и т. д. так же просто, как и одиночный объект. 
    
Простейшая форма графа сцены использует массив либо структуру данных связный список, а отображение его форм есть лишь последовательная итерация узлов один за другим. Другие общие операции, такие как определение, какая форма пересекается с курсором мыши (например, в приложениях, основанных на графическом интерфейсе пользователя) также осуществляются путём линейного поиска. Для небольших графов сцены этого обычно достаточно.

Более масштабные графы сцены приводят к заметному замедлению линейных операций, так что используются более сложные структуры хранения основных данных, наиболее популярная и общая форма — это дерево. В этих графах сцены составной шаблон проектирования зачастую призван создать иерархическое представление узлов группировки и листовых узлов. Сгруппированные узлы могут иметь любое количество прикреплённых дочерних узлов. Сгруппированные узлы включают узлы трансформаций и коммутационные узлы. Листовые узлы — это узлы, которые в действительности подлежат визуализации, либо узлы, на которых виден результат какого-либо действия. Они включают объекты, спрайты, звуки, источники освещения и всё, что может рассматриваться как подлежащее «рендерингу» в некотором абстрактном смысле. \\ \\
    \textbf{2. Свёрточная нейронная сеть}\\
    Идея свёрточных нейронных сетей заключается в чередовании свёрточных слоёв (англ. convolution layers) и субдискретизирующих слоёв. Структура сети — однонаправленная (без обратных связей), принципиально многослойная. Для обучения используются стандартные методы, чаще всего метод обратного распространения ошибки. Функция активации нейронов (передаточная функция) — любая, по выбору исследователя. \\
    
\textbf{\textit{Архитектура и принцип работы :}} 

В обычном перцептроне, который представляет собой полносвязную нейронную сеть, каждый нейрон связан со всеми нейронами предыдущего слоя, причём каждая связь имеет свой персональный весовой коэффициент. В свёрточной нейронной сети в операции свёртки используется лишь ограниченная матрица весов небольшого размера, которую «двигают» по всему обрабатываемому слою (в самом начале — непосредственно по входному изображению), формируя после каждого сдвига сигнал активации для нейрона следующего слоя с аналогичной позицией. То есть для различных нейронов выходного слоя используются одна и та же матрица весов, которую также называют ядром свёртки. Её интерпретируют как графическое кодирование какого-либо признака, например, наличие наклонной линии под определённым углом. Тогда следующий слой, получившийся в результате операции свёртки такой матрицей весов, показывает наличие данного признака в обрабатываемом слое и её координаты, формируя так называемую карту признаков (англ. feature map). Естественно, в свёрточной нейронной сети набор весов не один, а целая гамма, кодирующая элементы изображения (например линии и дуги под разными углами). При этом такие ядра свёртки не закладываются исследователем заранее, а формируются самостоятельно путём обучения сети классическим методом обратного распространения ошибки. Проход каждым набором весов формирует свой собственный экземпляр карты признаков, делая нейронную сеть многоканальной (много независимых карт признаков на одном слое). Также следует отметить, что при переборе слоя матрицей весов её передвигают обычно не на полный шаг (размер этой матрицы), а на небольшое расстояние. Так, например, при размерности матрицы весов 5×5 её сдвигают на один или два нейрона (пикселя) вместо пяти, чтобы не «перешагнуть» искомый признак.

Операция субдискретизации (англ. subsampling, англ. pooling, также переводимая как «операция подвыборки» или операция объединения), выполняет уменьшение размерности сформированных карт признаков. В данной архитектуре сети считается, что информация о факте наличия искомого признака важнее точного знания его координат, поэтому из нескольких соседних нейронов карты признаков выбирается максимальный и принимается за один нейрон уплотнённой карты признаков меньшей размерности. За счёт данной операции, помимо ускорения дальнейших вычислений, сеть становится более инвариантной к масштабу входного изображения.

Рассмотрим типовую структуру свёрточной нейронной сети более подробно. Сеть состоит из большого количества слоёв. После начального слоя (входного изображения) сигнал проходит серию свёрточных слоёв, в которых чередуется собственно свёртка и субдискретизация (пулинг). Чередование слоёв позволяет составлять «карты признаков» из карт признаков, на каждом следующем слое карта уменьшается в размере, но увеличивается количество каналов. На практике это означает способность распознавания сложных иерархий признаков. Обычно после прохождения нескольких слоёв карта признаков вырождается в вектор или даже скаляр, но таких карт признаков становятся сотни. На выходе свёрточных слоёв сети дополнительно устанавливают несколько слоёв полносвязной нейронной сети (перцептрон), на вход которому подаются оконечные карты признаков. \\

\textit{Слой свёртки. }Нейроны слоя свёртки, преобразуемые по нескольким выходным каналам
Слой свёртки (англ. convolutional layer) — это основной блок свёрточной нейронной сети. Слой свёртки включает в себя для каждого канала свой фильтр, ядро свёртки которого обрабатывает предыдущий слой по фрагментам (суммируя результаты поэлементного произведения для каждого фрагмента). Весовые коэффициенты ядра свёртки (небольшой матрицы) неизвестны и устанавливаются в процессе обучения.

Особенностью свёрточного слоя является сравнительно небольшое количество параметров, устанавливаемое при обучении. Так например, если исходное изображение имеет размерность 100×100 пикселей по трём каналам (это значит 30000 входных нейронов), а свёрточный слой использует фильтры c ядром 3x3 пикселя с выходом на 6 каналов, тогда в процессе обучения определяется только 9 весов ядра, однако по всем сочетаниям каналов, то есть 9×3×6 =162, в таком случае данный слой требует нахождения только 162 параметров, что существенно меньше количества искомых параметров полносвязной нейронной сети. \\

\textit{Слой активации. }Скалярный результат каждой свёртки попадает на функцию активации, которая представляет собой некую нелинейную функцию. Слой активации обычно логически объединяют со слоем свёртки (считают, что функция активации встроена в слой свёртки). Функция нелинейности может быть любой по выбору исследователя, традиционно для этого использовали функции типа гиперболического тангенса ({\displaystyle f(x)=\tanh(x)}{\displaystyle f(x)=\tanh(x)}, {\displaystyle f(x)=|\tanh(x)|}{\displaystyle f(x)=|\tanh(x)|}) или сигмоиды ({\displaystyle f(x)=(1+e^{-x})^{-1}}{\displaystyle f(x)=(1+e^{-x})^{-1}}). Однако в 2000х годах была предложена[4] и исследована новая функция активации — ReLU (сокращение от англ. rectified linear unit), которая позволила существенно ускорить процесс обучения и одновременно упростить вычисления (за счёт простоты самой функции), что означает блок линейной ректификации, вычисляющий функцию {\displaystyle f(x)=\max(0,x)}{\displaystyle f(x)=\max(0,x)}. То есть по сути это операция отсечения отрицательной части скалярной величины. По состоянию на 2017 год эта функция и её модификации (Noisy ReLU, Leaky ReLU и другие) являются наиболее часто используемыми функциями активации в глубоких нейросетях, в частности, в свёрточных. Существует методика определения оптимального числа блоков линейной ректификации. \\

\textit{Пулинг или слой субдискретизации. }Пулинг с функцией максимума и фильтром 2×2 с шагом 2
Слой пулинга (иначе подвыборки, субдискретизации) представляет собой нелинейное уплотнение карты признаков, при этом группа пикселей (обычно размера 2×2) уплотняется до одного пикселя, проходя нелинейное преобразование. Наиболее употребительна при этом функция максимума. Преобразования затрагивают непересекающиеся прямоугольники или квадраты, каждый из которых ужимается в один пиксель, при этом выбирается пиксель, имеющий максимальное значение. Операция пулинга позволяет существенно уменьшить пространственный объём изображения. Пулинг интерпретируется так: если на предыдущей операции свёртки уже были выявлены некоторые признаки, то для дальнейшей обработки настолько подробное изображение уже не нужно, и оно уплотняется до менее подробного. К тому же фильтрация уже ненужных деталей помогает не переобучаться. Слой пулинга, как правило, вставляется после слоя свёртки перед слоем следующей свёртки.

Кроме пулинга с функцией максимума можно использовать и другие функции — например, среднего значения или L2-нормирования. Однако практика показала преимущества именно пулинга с функцией максимума, который включается в типовые системы.

В целях более агрессивного уменьшения размера получаемых представлений, всё чаще находят распространение идеи использования меньших фильтров[8] или полный отказ от слоёв пулинга. \\ \\
    \textbf{3. Генеративно-состязательная сеть (GAN)}\\
    Алгоритм машинного обучения без учителя, построенный на комбинации из двух нейронных сетей, одна из которых (сеть G) генерирует образцы，а другая (сеть D) старается отличить правильные («подлинные») образцы от неправильных. Так как сети G и D имеют противоположные цели — создать образцы и отбраковать образцы — между ними возникает Антагонистическая игра. Генеративно-состязательную сеть описал Ян Гудфеллоу из компании Google в 2014 году.

    Использование этой техники позволяет в частности генерировать фотографии, которые человеческим глазом воспринимаются как натуральные изображения. \\
    
\textit{Дискриминатор. }Дискриминационные алгоритмы пытаются классифицировать входные данные. Учитывая особенности полученных данных, они стараются определить категорию, к которой они относятся.

К примеру, пробегая все слова в письме дискриминационный алгоритм может предсказать, является сообщение спамом или не спамом. Спам — это категория, а пакет слов, собранный из электронной почты — образы, которые составляют входные данные. Математически категории обозначают y, а образы обозначают x. Запись p(y|x) используется для обозначения «вероятности y при заданном x», которая обозначает «вероятность того, что электронное письмо является спамом при имеющемся наборе слов».

Итак, дискриминационные функции сопоставляют образы с категорией. Они заняты только этой корреляцией. \\

\textit{Генератор. }Генеративные алгоритмы заняты обратным. Вместо того, чтобы предсказывать категорию по имеющимся образам, они пытаются подобрать образы к данной категории.

В то время как дискриминационные алгоритмы волнует взаимосвязь между y и x, генеративные алгоритмы волнует “откуда берутся x”. Они позволяют находить p(x|y), вероятность x при данном y или вероятность образов при данном классе (генеративные алгоритмы также могут использоваться в качестве классификаторов. Они могут делать больше, чем классифицировать входные данные.)

Еще одно представление о работе генеративных алгоритмов можно получить, разделяя дискриминационные модели от генеративных таким образом: \\
1. Дискриминационные модели изучают границу между классами; \\
2. Генеративные модели моделируют распределение отдельных классов.\\ \\
\textbf{\textit{Как работают GAN}}

Одна нейронная сеть, называемая генератором, генерирует новые экземпляры данных, а другая — дискриминатор, оценивает их на подлинность; т.е. дискриминатор решает, относится ли каждый экземпляр данных, который он рассматривает, к набору тренировочных данных или нет.

Предположим, мы пытаемся сделать что-то более банальное, чем повторить портрет Моны Лизы. Мы сгенерируем рукописные цифры, подобные тем, что имеются в наборе данных MNIST. Цель дискриминатора — распознать подлинные экземпляры из набора.

Между тем, генератор создает новые изображения, которые он передает дискриминатору. Он делает это в надежде, что они будут приняты подлинными, хотя являются поддельными. Цель генератора состоит в том, чтобы генерировать рукописные цифры, которые будут пропущены дискриминатором. Цель дискриминатора — определить, является ли изображение подлинным. \\ \\
Шаги, которые проходит GAN : \\
1. Генератор получает рандомное число и возвращает изображение. \\
2. Это сгенерированное изображение подается в дискриминатор наряду с потоком изображений, взятых из фактического набора данных.\\
3. Дискриминатор принимает как реальные, так и поддельные изображения и возвращает вероятности, числа от 0 до 1, причем 1 представляет собой подлинное изображение и 0 представляет фальшивое. \\ \\
Таким образом, у есть двойной цикл обратной связи: \\
1. Дискриминатор находится в цикле с достоверными изображениями. \\
2. Генератор находится в цикле вместе с дискриминатором \\

Вы можете представить GAN как фальшивомонетчика и полицейского, играющих в кошки мышки, где фальсификатор учится изготавливать ложные купюры, а полицейский учится их обнаруживать. Оба динамичны; т. е. полицейский тоже тренируется (возможно, центральный банк отмечает пропущенные купюры), и каждая сторона приходит к изучению методов другого в постоянной эскалации.

Сеть дискриминаторов представляет собой стандартную сверточную сеть, которая может классифицировать изображения, подаваемые на нее с помощью биномиального классификатора, распознающего изображения как реальные или как поддельные. Генератор в некотором смысле представляет собой обратную сверточную сеть: хотя стандартный сверточный классификатор принимает изображение и уменьшает его разрешение, чтобы получить вероятность, генератор принимает вектор случайного шума и преобразует его в изображение. Первый отсеивает данные с помощью методов понижения дискретизации, таких как maxpooling, а второй генерирует новые данные.

Обе сети пытаются оптимизировать целевую функцию или функцию потерь в игре zero-zum. Это, по сути, модель актера-критика (actor-critic). Когда дискриминатор меняет свое поведение, то и генератор меняет, и наоборот. \\

\textit{Автокодеры и VAE. }Полезно сравнить генеративные состязательные сети с другими нейронными сетями, такими как автокодеры (автоэнкодеры) и вариационные автокодеры.

Автокодеры кодируют входные данные в векторы. Они создают скрытое или сжатое представление необработанных данных. Они полезны при уменьшении размерности: вектор, служащий в качестве скрытого представления, сжимает необработанные данные в меньшее количество. Автокодеры могут быть сопряжены с так называемым декодером, который позволяет восстанавливать входные данные на основе их скрытого представления, как и в случае с машиной Больцмана.

Вариационные автокодеры являются генеративным алгоритмом, который добавляет дополнительное ограничение для кодирования входных данных, а именно то, что скрытые представления нормализуются. Вариационные автокодеры способны сжимать данные как автокодеры и синтезировать данные подобно GAN. Однако, в то время как GAN генерируют данные детализовано, изображения, созданные VAE, бывают более размытыми. Примеры Deeplearning4j включают в себя как автокодеры, так и вариационные автокодеры.

Вы можете разделить генеративные алгоритмы на три типа, которые имея: \\
  1. категорию, предсказывают связанные функции (Naive Bayes); \\
  2. скрытое представление, предсказывают связанные функции (VAE, GAN); \\
  3. некоторые образы, предсказывают остальное (inpainting, imputation); \\ \\
    \textbf{4. Архитектура нейронной сети}\\
    1. Входные узлы (входной слой): вычислений в этих слоях нет, они просто передают информацию следующему слою.\\
    2. Скрытые узлы (скрытый слой): в скрытых слоях выполняется промежуточная обработка или вычисления, после чего происходит перенос весов с входного слоя на следующий слой.\\
    3. Выходные узлы (выходной слой): здесь мы наконец используем функцию активации.\\
    4. Соединения и веса: сеть состоит из соединений, каждое соединение передает выход нейрона i на вход нейрона j. В этом смысле i является предшественником j, а j является преемником i. Каждому соединению присваивается вес $W_{i,\;j}$.\\
    5. Функция активации: функция активации узла определяет выходные данные этого узла с учетом входных данных или набора входных данных. \\
    6. Правило обучения. Правило обучения - это правило или алгоритм, который изменяет параметры нейронной сети для того, чтобы данный вход в сеть создавал предпочтительный результат. Этот процесс обучения обычно сводится к изменению весов и порогов.\\
    
    \newpage
    \begin{center} 
    \section{Обзор источников}
    \end{center} 
    \large 
    На данную тему существует сравнительно немного литературы, что дает понять ее новизну и необходимость дальнейшего ее изучения.\\
    Несомненно, одним из наиболее важных аспектов работы являются данные, использованные для обучения моделей.\\
    Каждая статья отличается своим подходом к решению данной проблемы, но в большинстве своем они содержат в качестве составной части генеративно-состязательную сеть и различные ее модификации(ObjGAN, StackGAN, StackGAN++, AttnGAN и так далее).\\
    Каждый из существующих методов дает отличные от других результаты. Если попытаться обобщить, то можно сказать, что есть алгоритмы, прекрасно выполняющие свою задачу при несложной структуре сцены и маленьком количестве объектов, но показывающие плохие результаты при усложнении одного из критериев. Есть авторы, попытавшиеся расширить границы возможностей GAN в данной области. В данном отчете будут рассмотрены примеры из обеих выделенных мною категорий.\\
    А теперь уделим внимание данным, на которых обучались сети. Как говорил профессор Эндрю Ын в своих курсах: «В деле машинного обучения достигает успеха не тот, у кого есть наилучший алгоритм, а тот, у кого есть наилучшие данные». 
    Чаще всего используются стандартные наборы данных(Data set) с фотографиями и текстовым описанием интересующих объектов(в большей части статьей такими объектами являются птицы, цветы, иногда и лица людей).\\
    Далее приведен более подробный анализ двух конкретных статей :\\  - Image Generation from Scene Graphs, Justin Johnson, Agrim Gupta, Li Fei-Fei;\\  - AttnGAN: Fine-Grained Text to Image Generation
with Attentional Generative Adversarial Networks, Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He
    
    
    \newpage
    \begin{center} 
    \section{Разбор статей}
    % \huge \textbf{Разбор статей} \\[0.5cm]
    \subsection{Статья 1 : Генерация изображений по графу сцены}
    %   \huge Image Generation from Scene Graphs.\\
    %   \huge Justin Johnson, Agrim Gupta, Li Fei-Fei\\ [1.3cm]
    \end{center} 
      \large В данной части будет рассмотрена статья "Image Generation from Scene Graphs" Justin Johnson, Agrim Gupta, Li Fei-Fei []. Большинство существующих методов дают потрясающие результаты на ограниченных доменах, таких
как описания птиц или цветов, но не могут точно воспроизвести
сложные предложения со многими объектами и отношениями.\\
Для преодоления этого ограничения в данной статье авторы предлагают метод
генерирования изображений из графов сцен, позволяющих явно рассуждать об
объектах и их отношениях. Представленная в публикации модель использует свертку графа для
обработки входных графов, вычисляет макет сцены, прогнозируя границы
Bounding Box (BBox, ограничивающий параллелепипед) и маски сегментации для объектов, и преобразует макет в
изображение с каскадным уточнением сети.\\ \\
Основы метода :\\
Предложение представляет собой линейную структуру, в которой одно слово следует за другим; однако,
информация, передаваемая сложным предложением, часто может быть более явно представлена в виде графа сцены
объектов и их отношений.\\ \\
 - Для обработки входных данных графа сцены используется сеть свертки графа.\\
 - Для создания изображения, которое соответствует макету применяется cascaded refinement network (CRN), которая
обрабатывает макет.\\
 - Чтобы убедиться, что сгенерированные изображения реалистичны и содержат необходимые объекты разумно применить
генеративно-состязательные сети, работающие на патчах изображений и сгенерированных объектах.\\
 - Сквозной процесс обучения можно разделить на два основных компонента :\\ 
 Учебный компонент - первый этап, на котором машина записывает все параметры, выполняемые оператором (через
 Сверточные нейронные сети (CNN)). \\
  Компонент логического вывода возможен тогда, когда машина действует на основе ранее полученного опыта от компонента обучения сквозного процесса обучения. \\
  \begin{center}
  \includegraphics[scale=0.5]{scheme.jpg}
  \end{center}
  \\
  \begin{center} 
  \caption*{Рис. 1 - Схема, описывающая метод}
  \end{center} 
  \\
  \begin{center} 
  \includegraphics[scale=0.6]{sheep1.jpg}
  \\
  \caption*{Рис. 2 - Генерация графа сцены по предложению}
  \end{center} 
  \large Входом для описанной модели является граф сцены, описывающий объекты и связи между ними. Дан набор категорий объектов C и набор
категории R, граф сцены - это граф (O, E), где
O = {$ o_{1}$,. , , , $ o_{n}$} - множество объектов с каждым o $i \in C$, и
 $E \subseteq O \times R \times O $- 
 \large множество направленных ребер вида 
$($ o_{i}$, r, $ o_{j}$) где $ o_{i}$, $ o_{j}$ \in O и r \in R$. \\ \\
Конкретно, заданные входные векторы $ v_{i}$, $ v_{r}$ \in $R^D$ для всех
объектов $ $o_{i}$ \in O $ и ребра $ ($ o_{i}$, r, $o_{j}$) \in E $, вычисляем вывод
векторы для $ $v_{i}$^\prime$, $ $v_{r}$^\prime$ \in $R^D_{out} $ для всех узлов и ребер с использованием
три функции g s, g p и g o, которые принимают в качестве входных данных тройку
векторов ($v_{i}$, $v_{r}$, $v_{j}$) для ребра и вывод новых векторов
для субъекта $o_{i}$, предиката r и объекта $o_{j}$ соответственно.
Чтобы вычислить выходные векторы $ $v_{r}$^\prime$ для ребер, мы просто устанавливаем
$v_{r}$ = $g_{p}$ ($v_{i}$, $v_{r}$, $v_{j}$).\\
Аналогично использовалось $g_{o}$ для вычисления набора кандидатов $V^i_{o} $ для всех ребер, оканчивающихся на $o_{i}$. В частности,\\
$ $V^i_{s} $ = {$g_{s}$ ($v_{i}$, $v_{r}$, $v_{j}$): ($ o_{i}$, r, $ o_{j}$) \in E}$.\\
$ $V^i_{o} $ = {$g_{o}$ ($v_{j}$, $v_{r}$, $v_{i}$): ($ o_{j}$, r, $ o_{i}$ \in E}$.\\
Выходной вектор для объекта o i затем вычисляется как
$ $v_{i}$^\prime$ = h ($V^i_{s} $ \bigcup  $V^i_{o} $), где h - симметричная функция, которая
объединяет входной набор векторов в один выходной вектор.\\
  \begin{center} 
  \includegraphics[scale=0.4]{gr.png}
  \\
  \caption*{Рис. 3 - Вычислительный граф}
  \end{center} 
  \large Вычислительный граф, иллюстрирующий один граф сверточного слоя. Граф состоит из трех объектов $o_{1}$, $o_{2}$ и $o_{3}$ и
два ребра ($o_{1}$, $r_{1}$, $o_{2}$) и ($o_{3}$, $r_{2}$, $o_{2}$). Вдоль каждого края три
входные вектора передаются в функции $g_{s}$, $g_{p}$ и $g_{o}$; $g_{p}$ напрямую
вычисляет выходной вектор для ребра, а $g_{s}$ и $g_{o}$ вычисляют
векторы-кандидаты, которые подаются к симметричной функции пула
h для вычисления выходных векторов для объектов.\\ \\
Авторы генерируют реалистичные выходные изображения,
обучая сеть генерации изображений е состязательно
против пары дискриминаторных сетей $D_{img}$ и $D_{obj}$.
Дискриминатор D пытается классифицировать входные данные x как реальные
или поддельные путем максимизации $L_{GAN}$ = \underset{x \sim p_{real}}{E} log D (x) + \underset{x\sim p_{fake}}{E} log (1 - D (x))\\
где $x\sim$ $p_{fake}$ - выход из сети генерации f.
В то же время, f пытается генерировать выходные данные, которые будут
обмануть дискриминатор путем минимизации $L_{GAN}$.
$D_{img}$ дискриминатор изображения на основе патча обеспечивает
общий вид сгенерированных изображений реалистичен;
он классифицирует регулярно расположенный, перекрывающийся набор изображений
патчи как реальные или фальшивые.
Дискриминатор объекта $D_{obj}$ гарантирует, что каждый объект
на изображении выглядит реалистичным. В дополнение к классификации каждого объекта как
реальный или фальшивый, $D_{obj}$ также гарантирует, что каждый объект распознаваем, используя вспомогательный классификатор, который предсказывает
категория объекта; и $D_{obj}$, и F пытаются максимизировать
вероятность того, что $D_{obj}$ правильно классифицирует объекты.\\ \\

\begin{center} 
\subsection{Статья 2 : Генерация изображений по текстовому описанию с помощью генеративной сети внимания (Attentional Generative Adversarial Networks)}
    %   \huge AttnGAN: Fine-Grained Text to Image Generation
% with Attentional Generative Adversarial Networks.\\
    %   \hugeTao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He\\ [1.3cm]
    \end{center} 
      \large Рассмотрим статью "AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks" Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He. В этой статье предложена Attentional Generative Adversarial Network (AttnGAN), которая обеспечивает сосредоточенное,
многоэтапный синтез изображения из текста. Благодаря новой генеративной сети внимания AttnGAN можно синтезировать мелкозернистые детали в разных областях изображения, обращая внимание на соответствующие слова в описании на естественном языке.
Предложенная Генеративная Состязательная Сеть (AttnGAN) имеет два новых компонента: генеративная сеть с вниманием (attentional generative network) и глубокая
мультимодальная модель подобия внимания(the deep
attentional multimodal similarity model).\\

Описание метода :\\
Современные GAN-модели для генерации текста в изображения обычно кодируют целое предложение в текстовое описание в одном векторе как условие для генерации изображения, но не хватает детальной информации на уровне слов. В этом разделе авторы статьи предлагают новую модель внимания, которая позволяет генеративной сети рисовать различные субрегионы изображения, основанные на отношении к этим субрегионам.
Предложенная генеративная сеть внимания имеет m генераторов ($G_{0}$, $G_{1}$, ..., $G_{m - 1}$), которые берут скрытые состояния ($h_{0}$, $h_{1}$, ..., $h_{m - 1}$) в качестве входных данных и генерируют изображения малых и больших масштабов ($\hat{x^0}$, $\hat{x^1}$, ..., $\hat{x^{m - 1}}$).\\
В частности,
$h_{0}$ = $F_{0}$ (z, $F^{ca}$ (\overline{e}));\\
$h_{i}$ = $F_{i}$ ($h_{i - 1}$, $F^{attn}_{i} $(e, $h_{i - 1}$)) для i = 1, 2, ..., m - 1;\\
$\hat{x^i}$ = $G_{i}$ ($h_{i}$).

Здесь z - вектор шума, обычно выбираемый из стандартного нормального распределения, $\overline{e}$ является глобальным вектором предложения, а е является матрица векторов слов. $F^{ca}$ представляет собой кондиционирование
дополнение, которое преобразует вектор предложения e в
вектор кондиционирования. $F^{attn}$ - предлагаемая модель внимания на i-м этапе AttnGAN. $F^{ca}$, $F^{attn}_{i} $, $F_{i}$ и $G_{i}$ моделируются как нейронные сети.\\
Для создания реалистичных изображений с несколькими уровнями (т.е.
уровень предложения и уровень слова) условий, определяется конечная целевая функция генеративной сети внимания:\\
L = $L_{G}$ + $\lambda$ $L_{DAMSM}$, where $L_{G}$ = \sum_{\substack{
   i = 0 \\
   i < m−1
  }} 
 $L_{G_{i}}$\\
 
 Модель глубокого внимательного мультимодального сходства
DAMSM изучает две нейронные сети, которые отображают субрегионы изображения и слова предложения в общее семантическое пространство, таким образом, измеряет сходство изображения с текстом на уровне слова, чтобы вычислить мелкозернистые потери при генерации изображения.
\\
 \begin{center} 
  \includegraphics[scale=0.4]{ls.png}
  \\
  \caption*{Рис. 4 - Схема, описывающая метод}
  \end{center} 

\newpage
    \begin{center} 
    \section{Результаты практики}
    % \huge \textbf{Результаты практики} \\[0.5cm]
    \end{center} 
      \large Была предпринята попытка расширить теоретические знания в области нейронных сетей (в том числе применительно к задаче генерации изображений по текстовому описанию сцены).\\
      В результате работы был реализован простейший автокодировщик, являющийся составной частью одного из описанных методов.\\
      Так же была реализована простая версия одной из частей конволюционной(сверточной) нейронной сети. Выбрана именно конволюционная сеть, т.к. она(ее модификация) применяется в рассматриваемой в курсовой работе статье. \\
      Полученная модель дала следующие результаты :
      \begin{center} 
      \includegraphics[scale=0.5]{res.png}
      \\
      \caption*{Рис. 5 - Точность участка Training  против точности Validation. Простейший пример.}
      \end{center} 
\newpage
    \begin{center} 
    \section{Заключение}
    % \huge \textbf{Заключение} \\[0.5cm]
    \end{center} 
      \large В ходе проделанной работы были достигнуты поставленные цели.\\ \\
        1. Исследованы различные публикации на поставленную тему (2).\\
        2. Изучены средства и методы решения задачи синтеза изображений из их словесного описания.\\
        3. Проведены практические эксперименты.\\ \\ \\
    В дальнейшем планирую рассмотреть следующую литературу:\\ \\
        1. Generative Adversarial Networks Cookbook by Josh Kalin, December 2018
\\
        2. Photographic Text-to-Image Synthesis with a Hierarchically-nested Adversarial Network, Zizhao Zhang, Yuanpu Xie, Lin Yang\\
\newpage
    \begin{center} 
    \section{Ссылки}
    % \huge \textbf{Список литературы} \\[0.5cm]
    \end{center} 
      \large 
      Нейронные сети. Полный курс. Саймон Хайкин. Университет McMaster. Онтарио, Канада. \\
      1. AttnGAN: Fine-Grained Text to Image Generation
with Attentional Generative Adversarial Networks,
      Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He\\
      2. Image Generation from Scene Graphs,
      Justin Johnson, Agrim Gupta, Li Fei-Fei\\
      3. CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training, Jianmin Bao, Dong Chen, Fang Wen, Houqiang Li, Gang Hua\\
      4. StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks, Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, Dimitris Metaxas\\
      5. Text-to-Image Synthesis Based on Machine Generated Captions, Marco Menardi, Alex Falcon, Saida S.Mohamed, Lorenzo Seidenari, Giuseppe Serra, Alberto Del Bimbo and Carlo Tasso\\
      6. MirrorGAN: Learning Text-to-image Generation by Redescription Tingting Qiao, Jing Zhang, Duanqing Xu, and Dacheng Tao\\
      7. Object-driven Text-to-Image Synthesis via Adversarial Training, Wenbo Li, Pengchuan Zhang, Lei Zhang, Qiuyuan Huang, Xiaodong He, Siwei Lyu, Jianfeng Gao\\
      https://neurohive.io/ru/osnovy-data-science/osnovy-nejronnyh-setej-algoritmy-obuchenie-funkcii-aktivacii-i-poteri/ \\
      \\
      \\
      \\
      \\
      \\
      




\end{document}
