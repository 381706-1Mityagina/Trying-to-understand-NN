\documentclass{article}
\documentclass[utf8x, 12pt]{G7-32} % Стиль (по умолчанию будет 14pt)
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{mathtext}
\usepackage[numberright]{eskdplain}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{mathtext}
\usepackage[T1,T2A]{fontenc}
\usepackage[english,bulgarian,ukranian,russian]{babel}
\usepackage[argument]{graphicx}
\graphicspath{{pics/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\usepackage{geometry} % Меняем поля страницы
\geometry{left=2cm}% левое поле
\geometry{right=1.5cm}% правое поле
\geometry{top=1cm}% верхнее поле
\geometry{bottom=2cm}% нижнее поле

\begin{document}
    \begin{center} 
    \large МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ РОССИЙСКОЙ ФЕДЕРАЦИИ

федеральное государственное автономное образовательное учреждение высшего образования

Национальный исследовательский нижегородский государственный университет им. Н.И. Лобачевского

Институт информационных технологий, математики и механики \\
Кафедра теории управления и динамики систем \\[3.5cm] 
    
    \huge Отчёт по практике \\[0.6cm] % название работы, затем отступ 0,6см
    \\ 
    \huge{Тема :}\\[0.6cm]
    \huge Lower Frequencies\\[7.7cm]
    
    
    \end{center} 
    
    \begin{flushright}
    \large \textbf{Выполнил:} \\
    студент гр. 381703-2 \\
    Диженин Владислав Евгеньевич \\
    \textbf{Научный руководитель:} \\
    Специалист, инженер\\
    Середа Яна Александровна \\
    [3.7cm]
    \end{flushright}
    
    % \vfill 
    
    \begin{center} 
    \large Нижний Новгород 2020
    \end{center} 
    
    \thispagestyle{empty}
    \newpage
      \begin{center}
    %   Содержание
      \end{center}
        \tableofcontents
      
    \newpage
    \begin{center} 
    \section{Введение}
    %   \huge \textbf{Введение} \\[1.3cm]
    \end{center}
    \large 
    При обучении сетей есть низкие частоты и высокие. И чел вывел теорему, точнее доказал. Что чем ниже частота, тем быстрее будет происходить обучение. \\ ЗАМЕНИИИИИ\\
    Цели данной работы:\\
    \begin{enumerate} 
    \item изучение теории в данной области
    \item обзор реализованных программных решений поставленной задачи
    \item исследование существующих публикаций на выбранную тему
    \item изложение результатов некоторых проведенных экспериментов
    \end{enumerate} 
    \\
    
    \newpage
    \begin{center} 
    \section{Обзор источников}
    \large \textbf {On the Spectral Bias of Neural Networks, \\ Nasim Rahaman, Aristide Baratin, Devansh Arpit, Felix Draxler, Min Lin. Fred A. Hamprecht, Yoshua Bengio,Aaron Courville}    
    \end{center}
    \\
    \large 
    В этой работе авторы задались целью показать, что более низкая частота компоненты обученных сетей более устойчива к случайным возмущениям параметров. 
    \\
    Авторам статьи удалось:
    \begin{enumerate}
    \item применить непрерывную кусочно-линейную структуру сетей ReLU для оценки спектра Фурье
    \item найти эмпирическое доказательство спектрального смещения: т.е. более низкие частоты изучаются первыми. 
    \item изучить роль формы многообразия данных: показать, как сложные формы многообразия могут облегчить изучение высоких частот и разработку теоретического понимания этого поведения
    \end{enumerate}
    \\ \\
    Хотя нейронные сети могут аппроксимировать произвольные функции, авторы статьи находят, что эти сети приоритезируют изучение низкочастотных режимов, явление, называемое спектральным смещеним. Этот уклон проявляется не просто в процессе обучения, но и в параметризации модели: на самом деле, показано, что более низкая частота компоненты обученных сетей более устойчива к случайным возмущениям параметров.
    \\
    Рассмотрим составные части статьи более подробно.
    \\ \\
    \textbf {\textit{Фурье-анализ сетей ReLU}}
    \\
    Под «сеть ReLU» будем понимать скалярную функциию f : ${\mathbb{R}}^{d} \mapsto {\mathbb{R}}$, определяемую нейронной сетью с L скрытыми слоями шириной $d_1$, ... , $d_L$ и одним выходным нейроном:
    \\
    \begin{center} 
    f(x) $= (T^{(L+1)} \circ \sigma \circ T^{(L)} \circ $ ... $ \circ \sigma \circ T^{(1)})(x)$,
    \end{center}
    \\
    где T$^{(k)}$ : ${\mathbb{R}}^{d_{k-1}} \rightarrow {\mathbb{R}^{d_{k}}}$ - это аффинная функция ($d_0$ = d и $d_{L + 1}$ = 1) и $\sigma(u)_i$ = max(0, $u_i$) обозначает функцию активации ReLU, действующая поэлементно на вектор u = ($u_1$, ... , $u_n$).
    \\ 
    Учитывая сеть ReLU f из уравнения, приведенного выше, мы можем сделать кусочную линейность явной, написав
    \begin{center} 
    $f(x)= \sum\limits_{\epsilon} 1_{P_{\epsilon}}(x) (W_{\epsilon}x + b_{\epsilon})$
    \end{center}
    \\
    где ${\epsilon}$ индекс для линейных областей $P_{\epsilon}$ и $1_{P_{\epsilon}}$ это функция индикатора на $P_{\epsilon}$.
    \\ \\
    \textbf {\textit{Фурье Спектрум}}
    \\
    Далее мы рассмотрим структуру сетей ReLU с точки зрения их представления Фурье. Леммы 1 и 2 дают явный вид компонент Фурье.
    \\ \\
    \textit{Лемма 1:}
    \\
    Преобразование Фурье сетей ReLU раскладывается как:
    \\
    \begin{center} 
    $f(x)= i \sum\limits_{\epsilon} \frac{W_{\epsilon}k}{k^2} \tilde{1}_{P_{\epsilon}}(k) $
    \end{center}
    \\
    где $k = \Vert k \Vert$ и $\tilde{1}_{P_{\epsilon}}(k) = \int\limits_{P} e^{-ikx}dx$ это Фурье преобразование индикаторной функции P.
    \\
    \textit{Доказательство:}
    \\
    Вектор-функция
    $kf(x)e^{ikx}$ везде непрерывна и имеет четко определенные и непрерывные градиенты почти всюду. Так по теореме Стокса, интеграл его расходимости является чисто граничным слагаемым. Поскольку мы ограничены функциями с компактным носителем, теорема дает
    \begin{center}
    $\int\limits_{P} \bigtriangledown_{x} [ \textbf{k}f(x)e^{-i\textbf{kx}} ]$
    \end{center}
    \\ 
    Подынтегральное выражение есть: ($\textbf{k}(\bigtriangledown_{x}f)(x) - ik^{2}f(x)$)$e^{-\textbf{ikx}}$, поэтому выводим
    \begin{center}
    $\hat{f}(\textbf{k}) = \frac{1}{-ik^2}\textbf{k}$ $\int(\bigtriangledown_{x}f)(x)e^{-\textbf{ikx}}$
    \end{center}
    \\
    поэтому градиент f является постоянным вектором, $\bigtriangledown_{x}f_{\epsilon}$ = ${W_{\epsilon}}^{T}$, что дает желаемый результат.
    \\ \\
    \textit{Лемма 2:}
    \\
    Пусть P - многомерный многогранник в ${\mathbb{R}}^d$, его спектр Фурье принимает вид
    \begin{center}
    $\tilde{1}_{P}(\textbf{k}) = \sum\limits_{n=0}^{d}{\frac{D_n(\textbf{k})1_{G_{n}}(\textbf{k})}{k^n}}$ 
    \end{center}
    \\
    где $G_{n}$ - объединение n-мерных подпространств, ортогональных некоторой n-мерной грани P. 
    \\
    Леммы 1, 2 вместе дают основной результат этого раздела.
    \\ \\
    \textit{Теорема 1:}
    \\
    Фурье-компоненты сети ReLU $f_{\theta}$ с параметрами $\theta$ задается рациональной функцией:
    \begin{center}
    $\tilde{f}_{\theta}(\textbf{k}) = \sum\limits_{n=0}^{d}{\frac{C_n(\theta, \textbf{k})1_{{H_{n}}^{\theta}}(\textbf{k})}{k^{n+1}}}$ 
    \end{center}
    \\
    где ${{H_{n}}^{\theta}}$ является объединением n-мерных подпространств, ортогональных некоторым n-коразмерным граням некоторого многогранника
    \\ \\
    \textit{Обсуждение:}
    \\
    Сделаем следующие два замечания. Первое, спектральный распад сетей ReLU сильно анизотропен в больших размерах. Почти во всех направлениях ${\mathbb{R}}^d$, у нас есть $k^{−d − 1}$ распад. Тем не менее, распад может быть столь же медленным, как $k^{−2}$ в определенных направлениях, ортогональных к (d - 1)-мерному грани, ограничивающие линейные области
    \\
    Во-вторых, числитель в уравнении из леммы 2 ограничен $N_fL_f$, где $N_f$ - количество линейных областей, a $L_f = max_{\epsilon}\Vert W_{\epsilon} \Vert$ - постоянная Липшица сети.
    \\
    Кроме того, константа Липшица $L_f$ может быть ограничена как
    \begin{center}
    $L_f \leq \prod\limits_{k=1}^{L+1} \Vert W^{k} \Vert \leq {{\Vert \theta \Vert}_{\infty}}^{L+1} \surd{d} \prod\limits_{k=1}^{L}d_{k}$ 
    \end{center}
    \\
    где \Vert  \Vert - спектральная норма, а \Vert  \Vert$_{\infty}$ - максимальная норма, и $d_k$ - количество единиц в k-м слое
    \\ \\
    \newpage
    \begin{center} 
    \section{Результаты практики}
    %   \huge \textbf{Практика} \\[1.3cm]
    \end{center}
    \large
    
    \begin{center} 
    \includegraphics[scale=0.5]{graph.jpg}
    \\
    \caption{Рис. 1 - }
    \\ \\
    \end{center} 
    Эволюция спектра (ось X для частоты) во время тренировки (ось Y). Цвета показывают измеренную амплитуду спектра сети на соответствующей частоте, нормированной на целевую амплитуду на той же частоте и цветовая полоса ограничена от 0 до 1
    \begin{center} 
    \includegraphics[scale=0.5]{chart.jpg}
    \\
    \caption{Рис. 2 - }
    \\ \\
    \end{center} 
    
    \begin{center} 
    \includegraphics[scale=0.5]{layer.jpg}
    \\
    \caption{Рис. 3 - }
    \\ \\
    \end{center} 
    
    \newpage
    \begin{center} 
    \section{Заключение}
    %   \huge \textbf{Заключение} \\[1.3cm]
    \end{center}
    \large
    В ходе работы над данным проектом были достигнуты следующие цели:\\
    \begin{enumerate}
        \item изучены доступные решения поставленной задачи
        \item получены некоторые базовые знания
        \item часть этих знаний применена на практике
    \end{enumerate}
    \\ \\ \\
    В процессе изучения данной области, конечно, были и неудачи. Не удалось реализовать эффективный метод решения поставленной задачи, готова лишь часть необходимого функционала.
    \\ \\
    
    \newpage
    \begin{center} 
    \section{Приложение. Термины и определения.}
    %   \huge \textbf{Введение} \\[1.3cm]
    \end{center} 
    \large 
    \textit{1.}
    \textbf{Анализ Фурье} — направление в анализе, изучающее каким образом общие математические функции могут быть представлены либо приближены через сумму более простых тригонометрических функций. 
    \\ \\
    \textit{2.}
    \textbf{ReLU} - В последние годы большую популярность приобрела функция активации под названием «выпрямитель» (rectifier, по аналогии с однополупериодным выпрямителем в электротехнике). Нейроны с данной функцией активации называются ReLU (rectified linear unit). ReLU имеет следующую формулу f(x) = max(0, x) и реализует простой пороговый переход в нуле.
    \\ \\
    \textit{3.  []}
    \\
    \\ \\
    \textit{4.  []}
    \\
    \\ \\
    \textit{5.  []}
    \\
    \\ \\
    \textit{6. []}
    \\
    \\ \\
    \textit{7. []}
    \\
    \\ \\
    \textit{8.  []}
    \\
    \\ \\
    \textit{9. []}
    \\
    \\ \\
    
    \newpage
    \begin{center} 
    \section{Список литературы}
    %   \huge \textbf{Список литературы} \\[1.3cm]
    \end{center}
    \large
    \begin{enumerate} 
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
    \item 
    \end{enumerate}
    
\end{document}
