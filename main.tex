\documentclass{article}
\documentclass[utf8x, 12pt]{G7-32} % Стиль (по умолчанию будет 14pt)
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{mathtext}
\usepackage[numberright]{eskdplain}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{mathtext}
\usepackage[T1,T2A]{fontenc}
\usepackage[english,bulgarian,ukranian,russian]{babel}
\usepackage[argument]{graphicx}
\graphicspath{{pics/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\usepackage{geometry} % Меняем поля страницы
\geometry{left=2cm}% левое поле
\geometry{right=1.5cm}% правое поле
\geometry{top=1cm}% верхнее поле
\geometry{bottom=2cm}% нижнее поле

\begin{document}
    \begin{center} 
    \large МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ РОССИЙСКОЙ ФЕДЕРАЦИИ

Федеральное государственное автономное образовательное учреждение

Высшего образования

«Нижегородский государственный университет им. Н.И. Лобачевского»

Национальный исследовательский университет

Институт информационных технологий, математики и механики 
Кафедра математического обеспечения и суперкомпьютерных технологий\\[3.5cm] 
    
    \huge Отчёт по практике \\[0.6cm] % название работы, затем отступ 0,6см
    \\ 
    \huge{Тема :}\\[0.6cm]
    \huge Generative adversarial networks for Text-to-Image Synthesis\\[7.7cm]
    
    
    \end{center} 
    
    \begin{flushright}
    \large \textbf{Выполнил:} \\
    студент гр. 381706-1 \\
    Митягина Д.С. \\
    \textbf{Научный руководитель:} \\
    Профессор, доктор технических наук\\
    Турлапов В.Е. \\
    [3.7cm]
    \end{flushright}
    
    
    % \vfill 
    
    \begin{center} 
    \large Нижний Новгород 2019
    \end{center} 
    
    \thispagestyle{empty}
    \newpage
      \begin{center}
    %   Содержание
        \tableofcontents
      \end{center}
    \newpage
    \begin{center} 
    \section{Введение}
    %   \huge \textbf{Введение} \\[1.3cm]
    \end{center} 
      \large Oдной из самых сложных проблем в мире Computer Vision является синтез высококачественных изображений из текстовых описаний. Без сомнения, это интересно и полезно, но современные системы искусственного интеллекта далеки от этой цели.

    Генерация изображений имеет множество возможных применений в
    будущем, когда технологии будут готовы для коммерческого применения. 
    Люди смогут создавать схему расположения мебели для своего дома, просто описывая ее на компьютере, а не тратя много часов на поиск нужного дизайна.\\ 
    Создатели контента смогут творить в более тесном сотрудничестве с машиной, используя естественный язык.
    Кроме того, данная тема может стать более интересной, если ее развить. А именно, перевести задачу из генерации 2d изображения в построение 3d сцены и даже, возможно, формирование видео материалов с использование полученных сцен.\\ \\
    В данном отчете будут \\
    - рассмотрены уже существующие решения задачи генерации изображений по текстовому описанию\\
    - разобраны основные составляющие части программной реализации этих решений\\
    - описаны основные положения из теории, лежащие в основе выбранных методов\\
    - предъявлены результаты некоторых проведенных экспериментов\\
    \newpage
    \begin{center} 
    \section{Постановка задачи}
    % \huge \textbf{Постановка задачи} \\[1.3cm]
    \end{center} 
      \large 1. Исследовать различные публикации на поставленную тему.\\
             2. Изучить средства и методы решения задачи синтеза изображений из их словесного описания.\\
             3. Начать проведение практических экспериментов.\\
    \newpage
    \begin{center} 
    \section{Необходимый теоретический минимум}
    % \huge \textbf{Необходимый теоретический минимум} \\[1.3cm]
    \end{center} 
      \large \textbf{1. Граф сцены}\\
      Граф сцены представляет структуру, которая содержит логическое и зачастую (но не обязательно) пространственное представление графической сцены. Определение графа сцены нечёткое, поскольку программисты, осуществляющие его реализацию в приложениях, — и, в частности, в индустрии разработки игр — берут базовые принципы и адаптируют их для применения в конкретных приложениях. Это означает, что нет договорённости о том, каким должен быть граф сцены.

    Граф сцены представляет собой набор узлов такой структуры, как граф или дерево. Узел дерева (в предельной структуре дерева графа сцены) может иметь множество потомков, но зачастую только одного предка, причём действие предка распространяется на все его дочерние узлы; эффект действия, выполненного над группой, автоматически распространяется на все её элементы. Во многих программах ассоциирование матрицы преобразования (см. также трансформации и матрицы) на уровне любой группы и умножение таких матриц представляет собой эффективный и естественный способ обработки таких действий. Общей особенностью, к примеру, является способность группировать связанные формы/объекты в составной объект, который можно перемещать, трансформировать, выбирать и т. д. так же просто, как и одиночный объект. \\ \\
    \textbf{2. Свёрточная нейронная сеть}\\
    Идея свёрточных нейронных сетей заключается в чередовании свёрточных слоёв (англ. convolution layers) и субдискретизирующих слоёв. Структура сети — однонаправленная (без обратных связей), принципиально многослойная. Для обучения используются стандартные методы, чаще всего метод обратного распространения ошибки. Функция активации нейронов (передаточная функция) — любая, по выбору исследователя.  \\ \\
    \textbf{3. Генеративно-состязательная сеть (GAN)}\\
    Алгоритм машинного обучения без учителя, построенный на комбинации из двух нейронных сетей, одна из которых (сеть G) генерирует образцы，а другая (сеть D) старается отличить правильные («подлинные») образцы от неправильных. Так как сети G и D имеют противоположные цели — создать образцы и отбраковать образцы — между ними возникает Антагонистическая игра. Генеративно-состязательную сеть описал Ян Гудфеллоу из компании Google в 2014 году.

    Использование этой техники позволяет в частности генерировать фотографии, которые человеческим глазом воспринимаются как натуральные изображения.  \\ \\
    \textbf{4. Архитектура нейронной сети}\\
    1. Входные узлы (входной слой): вычислений в этих слоях нет, они просто передают информацию следующему слою.\\
    2. Скрытые узлы (скрытый слой): в скрытых слоях выполняется промежуточная обработка или вычисления, после чего происходит перенос весов с входного слоя на следующий слой.\\
    3. Выходные узлы (выходной слой): здесь мы наконец используем функцию активации.\\
    4. Соединения и веса: сеть состоит из соединений, каждое соединение передает выход нейрона i на вход нейрона j. В этом смысле i является предшественником j, а j является преемником i. Каждому соединению присваивается вес $W_{i,\;j}$.\\
    5. Функция активации: функция активации узла определяет выходные данные этого узла с учетом входных данных или набора входных данных. \\
    6. Правило обучения. Правило обучения - это правило или алгоритм, который изменяет параметры нейронной сети для того, чтобы данный вход в сеть создавал предпочтительный результат. Этот процесс обучения обычно сводится к изменению весов и порогов.\\
    
    \newpage
    \begin{center} 
    \section{Разбор статей}
    % \huge \textbf{Разбор статей} \\[0.5cm]
    \subsection{Статья 1 : Image Generation from Scene Graphs}
    %   \huge Image Generation from Scene Graphs.\\
      \huge Justin Johnson, Agrim Gupta, Li Fei-Fei\\ [1.3cm]
    \end{center} 
      \large Большинство существующих методов дают потрясающие результаты на ограниченных доменах, таких
как описания птиц или цветов, но не могут точно воспроизвести
сложные предложения со многими объектами и отношениями.\\
Для преодоления этого ограничения в данной статье авторы предлагают метод
генерирования изображений из графов сцен, позволяющих явно рассуждать об
объектах и их отношениях. Представленная в публикации модель использует свертку графа для
обработки входныч графов, вычисляет макет сцены, прогнозируя границы
Bounding Box (BBox, ограничивающий параллелепипед) и маски сегментации для объектов, и преобразует макет в
изображение с каскадным уточнением сети.\\ \\
Основы метода :\\
Предложение представляет собой линейную структуру, в которой одно слово следует за другим; однако,
информация, передаваемая сложным предложением, часто может быть более явно представлена в виде графа сцены
объектов и их отношений.\\ \\
 - Для обработки входных данных графа сцены используется сеть свертки графа.\\
 - Для создания изображения, которое соответствует макету применяется cascaded refinement network (CRN), которая
обрабатывает макет.\\
 - Чтобы убедиться, что сгенерированные изображения реалистичны и содержат необходимые объекты разумно применить
генеративно-состязательные сети, работающие на патчах изображений и сгенерированных объектах.\\
 - Сквозной процесс обучения можно разделить на два основных компонента :\\ 
 Учебный компонент - первый этап, на котором машина записывает все параметры, выполняемые оператором (через
 Сверточные нейронные сети (CNN)). \\
  Компонент логического вывода возможен тогда, когда машина действует на основе ранее полученного опыта от компонента обучения сквозного процесса обучения. \\
  \begin{center}
  \includegraphics[scale=0.5]{scheme.jpg}
  \end{center}
  \\
  \begin{center} 
  \caption*{Рис. 1 - Схема, описывающая метод}
  \end{center} 
  \\
  \begin{center} 
  \includegraphics[scale=0.6]{sheep1.jpg}
  \\
  \caption*{Рис. 2 - Генерация сцена графа по предложению}
  \end{center} 
  \large Входом для описанной модели является граф сцены, описывающий объекты и связи между ними. Дан набор категорий объектов C и набор
категории R, граф сцены - это граф (O, E), где
O = {$ o_{1}$,. , , , $ o_{n}$} - множество объектов с каждым o $i \in C$, и
 $E \subseteq O \times R \times O $- 
 \large множество направленных ребер вида 
$($ o_{i}$, r, $ o_{j}$) где $ o_{i}$, $ o_{j}$ \in O и r \in R$. \\ \\
Конкретно, заданные входные векторы $ v_{i}$, $ v_{r}$ \in $R^D$ для всех
объектов $ $o_{i}$ \in O $ и ребра $ ($ o_{i}$, r, $o_{j}$) \in E $, вычисляем вывод
векторы для $ $v_{i}$^\prime$, $ $v_{r}$^\prime$ \in $R^D_{out} $ для всех узлов и ребер с использованием
три функции g s, g p и g o, которые принимают в качестве входных данных тройку
векторов ($v_{i}$, $v_{r}$, $v_{j}$) для ребра и вывод новых векторов
для субъекта $o_{i}$, предиката r и объекта $o_{j}$ соответственно.
Чтобы вычислить выходные векторы $ $v_{r}$^\prime$ для ребер, мы просто устанавливаем
$v_{r}$ = $g_{p}$ ($v_{i}$, $v_{r}$, $v_{j}$).\\
Аналогично использовалось $g_{o}$ для вычисления набора кандидатов $V^i_{o} $ для всех ребер, оканчивающихся на $o_{i}$. В частности,\\
$ $V^i_{s} $ = {$g_{s}$ ($v_{i}$, $v_{r}$, $v_{j}$): ($ o_{i}$, r, $ o_{j}$) \in E}$.\\
$ $V^i_{o} $ = {$g_{o}$ ($v_{j}$, $v_{r}$, $v_{i}$): ($ o_{j}$, r, $ o_{i}$ \in E}$.\\
Выходной вектор для объекта o i затем вычисляется как
$ $v_{i}$^\prime$ = h ($V^i_{s} $ \bigcup  $V^i_{o} $), где h - симметричная функция, которая
объединяет входной набор векторов в один выходной вектор.\\
  \begin{center} 
  \includegraphics[scale=0.4]{gr.png}
  \\
  \caption*{Рис. 3 - Вычислительный граф}
  \end{center} 
  \large Вычислительный граф, иллюстрирующий один граф сверточного слоя. Граф состоит из трех объектов $o_{1}$, $o_{2}$ и $o_{3}$ и
два ребра ($o_{1}$, $r_{1}$, $o_{2}$) и ($o_{3}$, $r_{2}$, $o_{2}$). Вдоль каждого края три
входные вектора передаются в функции $g_{s}$, $g_{p}$ и $g_{o}$; $g_{p}$ напрямую
вычисляет выходной вектор для ребра, а $g_{s}$ и $g_{o}$ вычисляют
векторы-кандидаты, которые подаются к симметричной функции пула
h для вычисления выходных векторов для объектов.\\ \\
Авторы генерируют реалистичные выходные изображения,
обучая сеть генерации изображений е состязательно
против пары дискриминаторных сетей $D_{img}$ и $D_{obj}$.
Дискриминатор D пытается классифицировать входные данные x как реальные
или поддельные путем максимизации $L_{GAN}$ = \underset{x \sim p_{real}}{E} log D (x) + \underset{x\sim p_{fake}}{E} log (1 - D (x))\\
где $x\sim$ $p_{fake}$ - выход из сети генерации f.
В то же время, f пытается генерировать выходные данные, которые будут
обмануть дискриминатор путем минимизации $L_{GAN}$.
$D_{img}$ дискриминатор изображения на основе патча обеспечивает
общий вид сгенерированных изображений реалистичен;
он классифицирует регулярно расположенный, перекрывающийся набор изображений
патчи как реальные или фальшивые.
Дискриминатор объекта $D_{obj}$ гарантирует, что каждый объект
на изображении выглядит реалистичным; его входные данные являются пикселями
объект, обрезанный и масштабированный до фиксированного размера с помощью билинейного
интерполяция. В дополнение к классификации каждого объекта как
реальный или фальшивый, $D_{obj}$ также гарантирует, что каждый объект распознаваем, используя вспомогательный классификатор, который предсказывает
категория объекта; и $D_{obj}$, и F пытаются максимизировать
вероятность того, что $D_{obj}$ правильно классифицирует объекты.\\ \\

\begin{center} 
\subsection{Статья 2 : AttnGAN: Fine-Grained Text to Image Generation
with Attentional Generative Adversarial Networks}
    %   \huge AttnGAN: Fine-Grained Text to Image Generation
% with Attentional Generative Adversarial Networks.\\
      \hugeTao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He\\ [1.3cm]
    \end{center} 
      \large В этой статье предложена Attentional Generative Adversarial Network (AttnGAN), которая обеспечивает сосредоточенное,
многоэтапный синтез изображения из текста. Благодаря новой генеративной сети внимания AttnGAN можно синтезировать мелкозернистые детали в разных областях изображения, обращая внимание на соответствующие слова в описании на естественном языке.
Предложенная Генеративная Состязательная Сеть (AttnGAN) имеет два новых компонента: генеративная сеть с вниманием (attentional generative network) и глубокая
мультимодальная модель подобия внимания(the deep
attentional multimodal similarity model).\\

Описание метода :\\
Современные GAN-модели для генерации текста в изображения обычно кодируют целое предложение в текстовое описание в одном векторе как условие для генерации изображения, но не хватает детальной информации на уровне слов. В этом разделе авторы статьи предлагают новую модель внимания, которая позволяет генеративной сети рисовать различные субрегионы изображения, основанные на отношении к этим субрегионам.
Предложенная генеративная сеть внимания имеет m генераторов ($G_{0}$, $G_{1}$, ..., $G_{m - 1}$), которые берут скрытые состояния ($h_{0}$, $h_{1}$, ..., $h_{m - 1}$) в качестве входных данных и генерируют изображения малых и больших масштабов ($\hat{x^0}$, $\hat{x^1}$, ..., $\hat{x^{m - 1}}$).\\
В частности,
$h_{0}$ = $F_{0}$ (z, $F^{ca}$ (\overline{e}));\\
$h_{i}$ = $F_{i}$ ($h_{i - 1}$, $F^{attn}_{i} $(e, $h_{i - 1}$)) для i = 1, 2, ..., m - 1;\\
$\hat{x^i}$ = $G_{i}$ ($h_{i}$).

Здесь z - вектор шума, обычно выбираемый из стандартного нормального распределения, $\overline{e}$ является глобальным вектором предложения, а е является матрица векторов слов. $F^{ca}$ представляет собой кондиционирование
дополнение, которое преобразует вектор предложения e в
вектор кондиционирования. $F^{attn}$ - предлагаемая модель внимания на i-м этапе AttnGAN. $F^{ca}$, $F^{attn}_{i} $, $F_{i}$ и $G_{i}$ моделируются как нейронные сети.\\
Для создания реалистичных изображений с несколькими уровнями (т.е.
уровень предложения и уровень слова) условий, определяется конечная целевая функция генеративной сети внимания:\\
L = $L_{G}$ + $\lambda$ $L_{DAMSM}$, where $L_{G}$ = \sum_{\substack{
   i = 0 \\
   i < m−1
  }} 
 $L_{G_{i}}$\\
 
 Модель глубокого внимательного мультимодального сходства
DAMSM изучает две нейронные сети, которые отображают субрегионы изображения и слова предложения в общее семантическое пространство, таким образом, измеряет сходство изображения с текстом на уровне слова, чтобы вычислить мелкозернистые потери при генерации изображения.
\\
 \begin{center} 
  \includegraphics[scale=0.4]{ls.png}
  \\
  \caption*{Рис. 4 - Схема, описывающая метод}
  \end{center} 

\newpage
    \begin{center} 
    \section{Результаты практики}
    % \huge \textbf{Результаты практики} \\[0.5cm]
    \end{center} 
      \large Была предпринята попытка расширить теоретические знания в области нейронных сетей (в том числе применительно к задаче генерации изображений по текстовому описанию сцены).\\
      В результате работы был реализован простейший автокодировщик, являющийся составной частью одного из описанных методов.\\
      Так же была реализована простая версия одной из частей конволюционной(сверточной) нейронной сети. Выбрана именно конволюционная сеть, т.к. она(ее модификация) применяется в рассматриваемой в курсовой работе статье. \\
      Полученная модель дала следующие результаты :
      \begin{center} 
      \includegraphics[scale=0.5]{res.png}
      \\
      \caption*{Рис. 5 - Точность участка Training  против точности Validation. Простейший пример.}
      \end{center} 
\newpage
    \begin{center} 
    \section{Заключение}
    % \huge \textbf{Заключение} \\[0.5cm]
    \end{center} 
      \large В ходе проделанной работы были достигнуты поставленные цели.\\ \\
        1. Исследованы различные публикации на поставленную тему (2).\\
        2. Изучены средства и методы решения задачи синтеза изображений из их словесного описания.\\
        3. Проведены практические эксперименты.\\ \\ \\
    В дальнейшем планирую рассмотреть следующую литературу:\\ \\
        1. Generative Adversarial Networks Cookbook by Josh Kalin, December 2018
\\
        2. Photographic Text-to-Image Synthesis with a Hierarchically-nested Adversarial Network, Zizhao Zhang, Yuanpu Xie, Lin Yang\\
\newpage
    \begin{center} 
    \section{Список литературы}
    % \huge \textbf{Список литературы} \\[0.5cm]
    \end{center} 
      \large 1. AttnGAN: Fine-Grained Text to Image Generation
with Attentional Generative Adversarial Networks,
      Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He\\
      2. Image Generation from Scene Graphs,
      Justin Johnson, Agrim Gupta, Li Fei-Fei\\
      3. CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training, Jianmin Bao, Dong Chen, Fang Wen, Houqiang Li, Gang Hua\\
      4. StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks, Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, Dimitris Metaxas\\


\end{document}
